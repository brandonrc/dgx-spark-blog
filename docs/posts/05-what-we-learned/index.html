<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>What I Learned (And What&#39;s Next) | DGX Spark Deep Dive</title>
<meta name="keywords" content="dgx-spark, conclusions, recommendations, phase2">
<meta name="description" content="After 60 benchmarks and hours of debugging, here&#39;s what I learned about Grace Hopper, Docker, and the importance of understanding your full stack. Plus: what I&#39;m investigating next.">
<meta name="author" content="Brandon Geraci">
<link rel="canonical" href="https://brandonrc.github.io/dgx-spark-blog/posts/05-what-we-learned/">
<link crossorigin="anonymous" href="/dgx-spark-blog/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css" integrity="sha256-NDzEgLn/yPBMy&#43;XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://brandonrc.github.io/dgx-spark-blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://brandonrc.github.io/dgx-spark-blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://brandonrc.github.io/dgx-spark-blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://brandonrc.github.io/dgx-spark-blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://brandonrc.github.io/dgx-spark-blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://brandonrc.github.io/dgx-spark-blog/posts/05-what-we-learned/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script><meta property="og:url" content="https://brandonrc.github.io/dgx-spark-blog/posts/05-what-we-learned/">
  <meta property="og:site_name" content="DGX Spark Deep Dive">
  <meta property="og:title" content="What I Learned (And What&#39;s Next)">
  <meta property="og:description" content="After 60 benchmarks and hours of debugging, here&#39;s what I learned about Grace Hopper, Docker, and the importance of understanding your full stack. Plus: what I&#39;m investigating next.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-11-08T14:00:00+00:00">
    <meta property="article:modified_time" content="2025-11-08T14:00:00+00:00">
    <meta property="article:tag" content="Dgx-Spark">
    <meta property="article:tag" content="Conclusions">
    <meta property="article:tag" content="Recommendations">
    <meta property="article:tag" content="Phase2">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="What I Learned (And What&#39;s Next)">
<meta name="twitter:description" content="After 60 benchmarks and hours of debugging, here&#39;s what I learned about Grace Hopper, Docker, and the importance of understanding your full stack. Plus: what I&#39;m investigating next.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://brandonrc.github.io/dgx-spark-blog/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "What I Learned (And What's Next)",
      "item": "https://brandonrc.github.io/dgx-spark-blog/posts/05-what-we-learned/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "What I Learned (And What's Next)",
  "name": "What I Learned (And What\u0027s Next)",
  "description": "After 60 benchmarks and hours of debugging, here's what I learned about Grace Hopper, Docker, and the importance of understanding your full stack. Plus: what I'm investigating next.",
  "keywords": [
    "dgx-spark", "conclusions", "recommendations", "phase2"
  ],
  "articleBody": "The Journey So Far Let‚Äôs recap this wild ride:\nThe Problem: YouTube reviewers blamed NVIDIA hardware for being slow The Investigation: I found 20-30GB memory overhead in Docker containers The Environment Setup: MPI and chroot configuration nightmare The Revelation: Docker‚Äôs cgroups double-count unified memory The Data: 60 runs confirmed the pattern consistently Now, what do I actually do with this knowledge?\nKey Finding: Don‚Äôt Blame the Hardware The most important lesson from this entire investigation:\nHardware isn‚Äôt the problem when you haven‚Äôt understood the software stack.\nThose YouTube reviews that said ‚ÄúDGX Spark is slow‚Äù or ‚ÄúGrace Hopper is disappointing‚Äù? They were wrong. Not because the numbers were wrong, but because they stopped at the numbers.\nThe hardware is fine. The software assumptions are outdated.\nDocker‚Äôs cgroups were designed in an era of discrete GPUs where:\nCPU RAM and GPU VRAM are separate Memory spaces don‚Äôt overlap No double-counting is possible Grace Hopper introduced unified memory:\nOne coherent memory pool Both processors access the same RAM Elegant‚Ä¶ but Docker doesn‚Äôt understand it yet The lesson: Dig deeper. Understand the full stack. Don‚Äôt just blame the hardware.\nPractical Recommendations Based on my findings, here‚Äôs what I recommend:\nFor Large Models on Grace Hopper (\u003e 10B params): ‚úÖ Use Native/Chroot Execution\nWhy:\n20-30 GB memory savings 1.7-2.7x more KV cache No performance penalty Better resource utilization Trade-off: Less isolation, more setup complexity\nFor Small Models (\u003c 10B params): ü§î Docker is Acceptable\nIf 30GB overhead is acceptable for your use case:\nEasier deployment and management Better isolation for multi-tenancy Standard container tooling Simpler CI/CD integration For Discrete GPU Systems (H100, A100): ‚ö†Ô∏è This Finding is Grace Hopper Specific\nTraditional discrete GPU systems should NOT exhibit this pattern because:\nGPU VRAM is outside Docker‚Äôs cgroups No double-counting possible Standard container best practices apply The KV Cache Mystery (Phase 2) Here‚Äôs what really caught my attention: The relationship between container overhead and KV cache.\nLook at the pattern across all models:\nModel Native Total Container Total Overhead Native KV Container KV KV Reduction DeepSeek-7B 70.47 GiB 101.30 GiB +30.83 GiB 44.31 GiB 16.57 GiB -27.74 GiB Qwen-72B 70.03 GiB 90.02 GiB +19.99 GiB 44.71 GiB 26.72 GiB -17.99 GiB GPT-OSS-120B 71.72 GiB 93.43 GiB +21.71 GiB 43.19 GiB 23.65 GiB -19.54 GiB The Real Question: Where is that 20-30 GB container overhead going? And why does it result in lower KV cache allocation?\nHypothesis: Docker‚Äôs cgroups are double-counting unified memory, making TensorRT-LLM think it has less available memory. The framework then conservatively allocates less KV cache to avoid OOM errors.\nNotice:\nAll three models use ~44 GiB KV cache in native mode (very similar!) Container overhead directly correlates with KV cache reduction The overhead isn‚Äôt going to computation - it‚Äôs just‚Ä¶ disappearing Phase 2 Goal: Figure out exactly where the container overhead is going and why it prevents proper KV cache allocation.\nPhase 2: Deep Dive into Container Memory Accounting I‚Äôm planning a comprehensive Phase 2 investigation to understand exactly where that overhead is going:\nThe Plan Profile memory allocation in real-time\nUse nvidia-smi dmon during container vs native runs Track CUDA memory allocation patterns Monitor cgroup memory accounting vs actual GPU usage Test Docker memory configurations\nDifferent cgroup versions (v1 vs v2) Various --gpus configurations Test with --privileged mode Try --ipc=host and other isolation tweaks Instrument TensorRT-LLM\nAdd logging to see how much memory it thinks is available Track KV cache allocation decisions Compare memory queries between environments Compare with discrete GPUs\nRun same tests on H100/A100 system Confirm this is Grace Hopper unified memory specific Establish baseline for normal Docker behavior Key Questions to Answer Where is the 20-30 GB going? Is it actually allocated, or just counted differently? Why does TensorRT-LLM allocate less KV cache? What signal is it reading? Can Docker be configured to handle unified memory? Are there flags/configs we‚Äôre missing? Is this NVIDIA Container Toolkit specific? Would native containerd or podman behave differently? Expected Outcomes Pinpoint the exact mechanism causing double-counting Determine if there‚Äôs a Docker configuration fix Document whether this affects other unified memory systems (AMD MI300X, future Intel solutions) Provide concrete recommendations for Grace Hopper containerization Share Your Findings If you‚Äôre running Grace Hopper systems (or other unified memory architectures), I‚Äôd love to hear from you:\nAre you seeing similar patterns? Have you found workarounds? Do you have additional data to share? GitHub Repo: benchmark-spark\nOpen an issue or submit a PR with your findings!\nResources All the code, data, and analysis are open source:\nüìä Interactive Results: brandonrc.github.io/benchmark-spark üìÑ Full Analysis: ANALYSIS.md üîß Benchmark Scripts: scripts/ üì¶ Raw Data: results/comprehensive/ Final Thoughts This investigation reinforced something fundamental:\nModern AI infrastructure is a stack:\nHardware (Grace Hopper) Kernel (Linux cgroups) Drivers (NVIDIA, CUDA) Runtime (Docker, containerd) Software (TensorRT-LLM, PyTorch) Applications (Your LLM workload) A problem at any layer can look like a problem at any other layer.\nWhen something seems slow or inefficient, resist the urge to blame the most visible component (usually the hardware or the framework). Instead:\nMeasure everything - Get real data Isolate variables - Test different configurations Understand the stack - Know what each layer does Share findings - Help the community The YouTubers who blamed NVIDIA weren‚Äôt doing engineering. They were doing performance theater.\nI did engineering. And I found the real answer.\nWhat‚Äôs Your Experience? Have you encountered similar issues? Different findings? Better solutions?\nComment on GitHub Discussions Share your data Help me build Phase 2 Together, you and I can make GPU computing better for everyone - by actually understanding it instead of just pointing fingers.\nPrevious: ‚Üê Part 4: The Data - 60 Runs Don‚Äôt Lie Next: Part 6: KV Cache Deep Dive - The 2x Reduction Mystery ‚Üí\nGitHub Repo: benchmark-spark Phase 2 Tracking: GitHub Issues\nThanks for following along! üöÄ\n",
  "wordCount" : "964",
  "inLanguage": "en",
  "datePublished": "2025-11-08T14:00:00Z",
  "dateModified": "2025-11-08T14:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Brandon Geraci"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://brandonrc.github.io/dgx-spark-blog/posts/05-what-we-learned/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "DGX Spark Deep Dive",
    "logo": {
      "@type": "ImageObject",
      "url": "https://brandonrc.github.io/dgx-spark-blog/favicon.ico"
    }
  }
}
</script>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://brandonrc.github.io/dgx-spark-blog/" accesskey="h" title="DGX Spark Deep Dive (Alt + H)">DGX Spark Deep Dive</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://brandonrc.github.io/dgx-spark-blog/posts/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://brandonrc.github.io/dgx-spark-blog/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://github.com/brandonrc/benchmark-spark" title="Results">
                    <span>Results</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://brandonrc.github.io/dgx-spark-blog/">Home</a>&nbsp;¬ª&nbsp;<a href="https://brandonrc.github.io/dgx-spark-blog/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      What I Learned (And What&#39;s Next)
    </h1>
    <div class="post-description">
      After 60 benchmarks and hours of debugging, here&#39;s what I learned about Grace Hopper, Docker, and the importance of understanding your full stack. Plus: what I&#39;m investigating next.
    </div>
    <div class="post-meta"><span title='2025-11-08 14:00:00 +0000 +0000'>November 8, 2025</span>&nbsp;¬∑&nbsp;<span>5 min</span>&nbsp;¬∑&nbsp;<span>Brandon Geraci</span>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#the-journey-so-far" aria-label="The Journey So Far">The Journey So Far</a></li>
                <li>
                    <a href="#key-finding-dont-blame-the-hardware" aria-label="Key Finding: Don&rsquo;t Blame the Hardware">Key Finding: Don&rsquo;t Blame the Hardware</a></li>
                <li>
                    <a href="#practical-recommendations" aria-label="Practical Recommendations">Practical Recommendations</a><ul>
                        
                <li>
                    <a href="#for-large-models-on-grace-hopper--10b-params" aria-label="For Large Models on Grace Hopper (&gt; 10B params):">For Large Models on Grace Hopper (&gt; 10B params):</a></li>
                <li>
                    <a href="#for-small-models--10b-params" aria-label="For Small Models (&lt; 10B params):">For Small Models (&lt; 10B params):</a></li>
                <li>
                    <a href="#for-discrete-gpu-systems-h100-a100" aria-label="For Discrete GPU Systems (H100, A100):">For Discrete GPU Systems (H100, A100):</a></li></ul>
                </li>
                <li>
                    <a href="#the-kv-cache-mystery-phase-2" aria-label="The KV Cache Mystery (Phase 2)">The KV Cache Mystery (Phase 2)</a></li>
                <li>
                    <a href="#phase-2-deep-dive-into-container-memory-accounting" aria-label="Phase 2: Deep Dive into Container Memory Accounting">Phase 2: Deep Dive into Container Memory Accounting</a><ul>
                        
                <li>
                    <a href="#the-plan" aria-label="The Plan">The Plan</a></li>
                <li>
                    <a href="#key-questions-to-answer" aria-label="Key Questions to Answer">Key Questions to Answer</a></li>
                <li>
                    <a href="#expected-outcomes" aria-label="Expected Outcomes">Expected Outcomes</a></li></ul>
                </li>
                <li>
                    <a href="#share-your-findings" aria-label="Share Your Findings">Share Your Findings</a></li>
                <li>
                    <a href="#resources" aria-label="Resources">Resources</a></li>
                <li>
                    <a href="#final-thoughts" aria-label="Final Thoughts">Final Thoughts</a></li>
                <li>
                    <a href="#whats-your-experience" aria-label="What&rsquo;s Your Experience?">What&rsquo;s Your Experience?</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="the-journey-so-far">The Journey So Far<a hidden class="anchor" aria-hidden="true" href="#the-journey-so-far">#</a></h2>
<p>Let&rsquo;s recap this wild ride:</p>
<ol>
<li><strong>The Problem</strong>: YouTube reviewers blamed NVIDIA hardware for being slow</li>
<li><strong>The Investigation</strong>: I found 20-30GB memory overhead in Docker containers</li>
<li><strong>The Environment Setup</strong>: MPI and chroot configuration nightmare</li>
<li><strong>The Revelation</strong>: Docker&rsquo;s cgroups double-count unified memory</li>
<li><strong>The Data</strong>: 60 runs confirmed the pattern consistently</li>
</ol>
<p>Now, what do I actually <strong>do</strong> with this knowledge?</p>
<h2 id="key-finding-dont-blame-the-hardware">Key Finding: Don&rsquo;t Blame the Hardware<a hidden class="anchor" aria-hidden="true" href="#key-finding-dont-blame-the-hardware">#</a></h2>
<p>The most important lesson from this entire investigation:</p>
<p><strong>Hardware isn&rsquo;t the problem when you haven&rsquo;t understood the software stack.</strong></p>
<p>Those YouTube reviews that said &ldquo;DGX Spark is slow&rdquo; or &ldquo;Grace Hopper is disappointing&rdquo;? They were wrong. Not because the numbers were wrong, but because they <strong>stopped at the numbers</strong>.</p>
<p>The hardware is fine. The software assumptions are outdated.</p>
<p>Docker&rsquo;s cgroups were designed in an era of discrete GPUs where:</p>
<ul>
<li>CPU RAM and GPU VRAM are separate</li>
<li>Memory spaces don&rsquo;t overlap</li>
<li>No double-counting is possible</li>
</ul>
<p>Grace Hopper introduced unified memory:</p>
<ul>
<li>One coherent memory pool</li>
<li>Both processors access the same RAM</li>
<li>Elegant&hellip; but Docker doesn&rsquo;t understand it yet</li>
</ul>
<p><strong>The lesson</strong>: Dig deeper. Understand the full stack. Don&rsquo;t just blame the hardware.</p>
<h2 id="practical-recommendations">Practical Recommendations<a hidden class="anchor" aria-hidden="true" href="#practical-recommendations">#</a></h2>
<p>Based on my findings, here&rsquo;s what I recommend:</p>
<h3 id="for-large-models-on-grace-hopper--10b-params">For Large Models on Grace Hopper (&gt; 10B params):<a hidden class="anchor" aria-hidden="true" href="#for-large-models-on-grace-hopper--10b-params">#</a></h3>
<p><strong>‚úÖ Use Native/Chroot Execution</strong></p>
<p>Why:</p>
<ul>
<li>20-30 GB memory savings</li>
<li>1.7-2.7x more KV cache</li>
<li>No performance penalty</li>
<li>Better resource utilization</li>
</ul>
<p>Trade-off: Less isolation, more setup complexity</p>
<h3 id="for-small-models--10b-params">For Small Models (&lt; 10B params):<a hidden class="anchor" aria-hidden="true" href="#for-small-models--10b-params">#</a></h3>
<p><strong>ü§î Docker is Acceptable</strong></p>
<p>If 30GB overhead is acceptable for your use case:</p>
<ul>
<li>Easier deployment and management</li>
<li>Better isolation for multi-tenancy</li>
<li>Standard container tooling</li>
<li>Simpler CI/CD integration</li>
</ul>
<h3 id="for-discrete-gpu-systems-h100-a100">For Discrete GPU Systems (H100, A100):<a hidden class="anchor" aria-hidden="true" href="#for-discrete-gpu-systems-h100-a100">#</a></h3>
<p><strong>‚ö†Ô∏è This Finding is Grace Hopper Specific</strong></p>
<p>Traditional discrete GPU systems should NOT exhibit this pattern because:</p>
<ul>
<li>GPU VRAM is outside Docker&rsquo;s cgroups</li>
<li>No double-counting possible</li>
<li>Standard container best practices apply</li>
</ul>
<h2 id="the-kv-cache-mystery-phase-2">The KV Cache Mystery (Phase 2)<a hidden class="anchor" aria-hidden="true" href="#the-kv-cache-mystery-phase-2">#</a></h2>
<p>Here&rsquo;s what really caught my attention: <strong>The relationship between container overhead and KV cache</strong>.</p>
<p>Look at the pattern across all models:</p>
<table>
  <thead>
      <tr>
          <th>Model</th>
          <th>Native Total</th>
          <th>Container Total</th>
          <th>Overhead</th>
          <th>Native KV</th>
          <th>Container KV</th>
          <th>KV Reduction</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>DeepSeek-7B</td>
          <td>70.47 GiB</td>
          <td>101.30 GiB</td>
          <td><strong>+30.83 GiB</strong></td>
          <td>44.31 GiB</td>
          <td>16.57 GiB</td>
          <td><strong>-27.74 GiB</strong></td>
      </tr>
      <tr>
          <td>Qwen-72B</td>
          <td>70.03 GiB</td>
          <td>90.02 GiB</td>
          <td><strong>+19.99 GiB</strong></td>
          <td>44.71 GiB</td>
          <td>26.72 GiB</td>
          <td><strong>-17.99 GiB</strong></td>
      </tr>
      <tr>
          <td>GPT-OSS-120B</td>
          <td>71.72 GiB</td>
          <td>93.43 GiB</td>
          <td><strong>+21.71 GiB</strong></td>
          <td>43.19 GiB</td>
          <td>23.65 GiB</td>
          <td><strong>-19.54 GiB</strong></td>
      </tr>
  </tbody>
</table>
<p><strong>The Real Question</strong>: Where is that 20-30 GB container overhead going? And why does it result in lower KV cache allocation?</p>
<p><strong>Hypothesis</strong>: Docker&rsquo;s cgroups are double-counting unified memory, making TensorRT-LLM think it has less available memory. The framework then conservatively allocates less KV cache to avoid OOM errors.</p>
<p>Notice:</p>
<ul>
<li>All three models use <strong>~44 GiB KV cache in native mode</strong> (very similar!)</li>
<li>Container overhead directly correlates with KV cache reduction</li>
<li>The overhead isn&rsquo;t going to computation - it&rsquo;s just&hellip; disappearing</li>
</ul>
<p><strong>Phase 2 Goal</strong>: Figure out exactly where the container overhead is going and why it prevents proper KV cache allocation.</p>
<h2 id="phase-2-deep-dive-into-container-memory-accounting">Phase 2: Deep Dive into Container Memory Accounting<a hidden class="anchor" aria-hidden="true" href="#phase-2-deep-dive-into-container-memory-accounting">#</a></h2>
<p>I&rsquo;m planning a comprehensive Phase 2 investigation to understand exactly where that overhead is going:</p>
<h3 id="the-plan">The Plan<a hidden class="anchor" aria-hidden="true" href="#the-plan">#</a></h3>
<ol>
<li>
<p><strong>Profile memory allocation in real-time</strong></p>
<ul>
<li>Use <code>nvidia-smi dmon</code> during container vs native runs</li>
<li>Track CUDA memory allocation patterns</li>
<li>Monitor cgroup memory accounting vs actual GPU usage</li>
</ul>
</li>
<li>
<p><strong>Test Docker memory configurations</strong></p>
<ul>
<li>Different cgroup versions (v1 vs v2)</li>
<li>Various <code>--gpus</code> configurations</li>
<li>Test with <code>--privileged</code> mode</li>
<li>Try <code>--ipc=host</code> and other isolation tweaks</li>
</ul>
</li>
<li>
<p><strong>Instrument TensorRT-LLM</strong></p>
<ul>
<li>Add logging to see how much memory it thinks is available</li>
<li>Track KV cache allocation decisions</li>
<li>Compare memory queries between environments</li>
</ul>
</li>
<li>
<p><strong>Compare with discrete GPUs</strong></p>
<ul>
<li>Run same tests on H100/A100 system</li>
<li>Confirm this is Grace Hopper unified memory specific</li>
<li>Establish baseline for normal Docker behavior</li>
</ul>
</li>
</ol>
<h3 id="key-questions-to-answer">Key Questions to Answer<a hidden class="anchor" aria-hidden="true" href="#key-questions-to-answer">#</a></h3>
<ul>
<li><strong>Where is the 20-30 GB going?</strong> Is it actually allocated, or just counted differently?</li>
<li><strong>Why does TensorRT-LLM allocate less KV cache?</strong> What signal is it reading?</li>
<li><strong>Can Docker be configured to handle unified memory?</strong> Are there flags/configs we&rsquo;re missing?</li>
<li><strong>Is this NVIDIA Container Toolkit specific?</strong> Would native containerd or podman behave differently?</li>
</ul>
<h3 id="expected-outcomes">Expected Outcomes<a hidden class="anchor" aria-hidden="true" href="#expected-outcomes">#</a></h3>
<ul>
<li>Pinpoint the exact mechanism causing double-counting</li>
<li>Determine if there&rsquo;s a Docker configuration fix</li>
<li>Document whether this affects other unified memory systems (AMD MI300X, future Intel solutions)</li>
<li>Provide concrete recommendations for Grace Hopper containerization</li>
</ul>
<h2 id="share-your-findings">Share Your Findings<a hidden class="anchor" aria-hidden="true" href="#share-your-findings">#</a></h2>
<p>If you&rsquo;re running Grace Hopper systems (or other unified memory architectures), I&rsquo;d love to hear from you:</p>
<ul>
<li>Are you seeing similar patterns?</li>
<li>Have you found workarounds?</li>
<li>Do you have additional data to share?</li>
</ul>
<p><strong>GitHub Repo</strong>: <a href="https://github.com/brandonrc/benchmark-spark">benchmark-spark</a><br>
<strong>Open an issue</strong> or <strong>submit a PR</strong> with your findings!</p>
<h2 id="resources">Resources<a hidden class="anchor" aria-hidden="true" href="#resources">#</a></h2>
<p>All the code, data, and analysis are open source:</p>
<ul>
<li><strong>üìä Interactive Results</strong>: <a href="https://brandonrc.github.io/benchmark-spark/">brandonrc.github.io/benchmark-spark</a></li>
<li><strong>üìÑ Full Analysis</strong>: <a href="https://github.com/brandonrc/benchmark-spark/blob/main/ANALYSIS.md">ANALYSIS.md</a></li>
<li><strong>üîß Benchmark Scripts</strong>: <a href="https://github.com/brandonrc/benchmark-spark/tree/main/scripts">scripts/</a></li>
<li><strong>üì¶ Raw Data</strong>: <a href="https://github.com/brandonrc/benchmark-spark/tree/main/results/comprehensive">results/comprehensive/</a></li>
</ul>
<h2 id="final-thoughts">Final Thoughts<a hidden class="anchor" aria-hidden="true" href="#final-thoughts">#</a></h2>
<p>This investigation reinforced something fundamental:</p>
<p><strong>Modern AI infrastructure is a stack</strong>:</p>
<ul>
<li>Hardware (Grace Hopper)</li>
<li>Kernel (Linux cgroups)</li>
<li>Drivers (NVIDIA, CUDA)</li>
<li>Runtime (Docker, containerd)</li>
<li>Software (TensorRT-LLM, PyTorch)</li>
<li>Applications (Your LLM workload)</li>
</ul>
<p>A problem at any layer can look like a problem at any other layer.</p>
<p>When something seems slow or inefficient, resist the urge to blame the most visible component (usually the hardware or the framework). Instead:</p>
<ol>
<li><strong>Measure everything</strong> - Get real data</li>
<li><strong>Isolate variables</strong> - Test different configurations</li>
<li><strong>Understand the stack</strong> - Know what each layer does</li>
<li><strong>Share findings</strong> - Help the community</li>
</ol>
<p>The YouTubers who blamed NVIDIA weren&rsquo;t doing engineering. They were doing performance theater.</p>
<p>I did engineering. And I found the real answer.</p>
<hr>
<h2 id="whats-your-experience">What&rsquo;s Your Experience?<a hidden class="anchor" aria-hidden="true" href="#whats-your-experience">#</a></h2>
<p>Have you encountered similar issues? Different findings? Better solutions?</p>
<ul>
<li>Comment on <a href="https://github.com/brandonrc/benchmark-spark/discussions">GitHub Discussions</a></li>
<li>Share your data</li>
<li>Help me build Phase 2</li>
</ul>
<p>Together, you and I can make GPU computing better for everyone - by actually understanding it instead of just pointing fingers.</p>
<hr>
<p><strong>Previous</strong>: <a href="../04-the-data">‚Üê Part 4: The Data - 60 Runs Don&rsquo;t Lie</a>
<strong>Next</strong>: <a href="../06-kv-cache-deep-dive">Part 6: KV Cache Deep Dive - The 2x Reduction Mystery ‚Üí</a></p>
<p><strong>GitHub Repo</strong>: <a href="https://github.com/brandonrc/benchmark-spark">benchmark-spark</a>
<strong>Phase 2 Tracking</strong>: <a href="https://github.com/brandonrc/benchmark-spark/issues">GitHub Issues</a></p>
<hr>
<p><strong>Thanks for following along!</strong> üöÄ</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://brandonrc.github.io/dgx-spark-blog/tags/dgx-spark/">Dgx-Spark</a></li>
      <li><a href="https://brandonrc.github.io/dgx-spark-blog/tags/conclusions/">Conclusions</a></li>
      <li><a href="https://brandonrc.github.io/dgx-spark-blog/tags/recommendations/">Recommendations</a></li>
      <li><a href="https://brandonrc.github.io/dgx-spark-blog/tags/phase2/">Phase2</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://brandonrc.github.io/dgx-spark-blog/posts/06-kv-cache-deep-dive/">
    <span class="title">¬´ Prev</span>
    <br>
    <span>KV Cache Deep Dive: The 2x Reduction Mystery</span>
  </a>
  <a class="next" href="https://brandonrc.github.io/dgx-spark-blog/posts/04-the-data/">
    <span class="title">Next ¬ª</span>
    <br>
    <span>The Data: 60 Runs Don&#39;t Lie</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share What I Learned (And What&#39;s Next) on x"
            href="https://x.com/intent/tweet/?text=What%20I%20Learned%20%28And%20What%27s%20Next%29&amp;url=https%3a%2f%2fbrandonrc.github.io%2fdgx-spark-blog%2fposts%2f05-what-we-learned%2f&amp;hashtags=dgx-spark%2cconclusions%2crecommendations%2cphase2">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share What I Learned (And What&#39;s Next) on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fbrandonrc.github.io%2fdgx-spark-blog%2fposts%2f05-what-we-learned%2f&amp;title=What%20I%20Learned%20%28And%20What%27s%20Next%29&amp;summary=What%20I%20Learned%20%28And%20What%27s%20Next%29&amp;source=https%3a%2f%2fbrandonrc.github.io%2fdgx-spark-blog%2fposts%2f05-what-we-learned%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share What I Learned (And What&#39;s Next) on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fbrandonrc.github.io%2fdgx-spark-blog%2fposts%2f05-what-we-learned%2f&title=What%20I%20Learned%20%28And%20What%27s%20Next%29">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share What I Learned (And What&#39;s Next) on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fbrandonrc.github.io%2fdgx-spark-blog%2fposts%2f05-what-we-learned%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share What I Learned (And What&#39;s Next) on whatsapp"
            href="https://api.whatsapp.com/send?text=What%20I%20Learned%20%28And%20What%27s%20Next%29%20-%20https%3a%2f%2fbrandonrc.github.io%2fdgx-spark-blog%2fposts%2f05-what-we-learned%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share What I Learned (And What&#39;s Next) on telegram"
            href="https://telegram.me/share/url?text=What%20I%20Learned%20%28And%20What%27s%20Next%29&amp;url=https%3a%2f%2fbrandonrc.github.io%2fdgx-spark-blog%2fposts%2f05-what-we-learned%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share What I Learned (And What&#39;s Next) on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=What%20I%20Learned%20%28And%20What%27s%20Next%29&u=https%3a%2f%2fbrandonrc.github.io%2fdgx-spark-blog%2fposts%2f05-what-we-learned%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://brandonrc.github.io/dgx-spark-blog/">DGX Spark Deep Dive</a></span> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
